#!/usr/bin/env python3
"""
ØªÙ†Ø¸ÙŠÙ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© - Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙˆØ¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª
"""

import sqlite3
import os
import json
from datetime import datetime, timedelta

class KnowledgeCleaner:
    def __init__(self):
        self.knowledge_db = "data/knowledge/knowledge.db"
    
    def analyze_content(self):
        """ØªØ­Ù„ÙŠÙ„ Ù…Ø­ØªÙˆÙ‰ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©"""
        print("ðŸ” ØªØ­Ù„ÙŠÙ„ Ù…Ø­ØªÙˆÙ‰ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©...")
        
        try:
            conn = sqlite3.connect(self.knowledge_db)
            cursor = conn.cursor()
            
            # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¹Ø§Ù…Ø©
            cursor.execute('SELECT COUNT(*) FROM web_knowledge')
            total = cursor.fetchone()[0]
            
            cursor.execute('SELECT COUNT(DISTINCT url) FROM web_knowledge')
            unique_urls = cursor.fetchone()[0]
            
            cursor.execute('SELECT COUNT(DISTINCT category) FROM web_knowledge')
            categories = cursor.fetchone()[0]
            
            # Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙƒØ±Ø± (Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ù†ÙˆØ§Ù†)
            cursor.execute('''
                SELECT title, COUNT(*) as count 
                FROM web_knowledge 
                GROUP BY title 
                HAVING COUNT(*) > 1
            ''')
            duplicate_titles = cursor.fetchall()
            
            # Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù‚Ø¯ÙŠÙ… (Ø£ÙƒØ«Ø± Ù…Ù† 30 ÙŠÙˆÙ…)
            cursor.execute('''
                SELECT COUNT(*) 
                FROM web_knowledge 
                WHERE created_at < datetime("now", "-30 days")
            ''')
            old_content = cursor.fetchone()[0]
            
            conn.close()
            
            report = {
                "total_records": total,
                "unique_urls": unique_urls,
                "categories_count": categories,
                "duplicate_titles": len(duplicate_titles),
                "old_content": old_content,
                "analysis_date": datetime.now().isoformat()
            }
            
            return report
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {e}")
            return {}
    
    def remove_duplicates(self):
        """Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙƒØ±Ø±"""
        print("ðŸ§¹ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙƒØ±Ø±...")
        
        try:
            conn = sqlite3.connect(self.knowledge_db)
            cursor = conn.cursor()
            
            # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…ÙƒØ±Ø±Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† (Ù…Ø¹ Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø£Ø­Ø¯Ø« Ø³Ø¬Ù„)
            cursor.execute('''
                DELETE FROM web_knowledge 
                WHERE id NOT IN (
                    SELECT MIN(id) 
                    FROM web_knowledge 
                    GROUP BY title
                )
            ''')
            
            deleted_count = cursor.rowcount
            conn.commit()
            conn.close()
            
            print(f"âœ… ØªÙ… Ø­Ø°Ù {deleted_count} Ø³Ø¬Ù„ Ù…ÙƒØ±Ø±")
            return deleted_count
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…ÙƒØ±Ø±Ø§Øª: {e}")
            return 0
    
    def remove_old_content(self, days=30):
        """Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù‚Ø¯ÙŠÙ…"""
        print(f"ðŸ—‘ï¸  Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø£Ù‚Ø¯Ù… Ù…Ù† {days} ÙŠÙˆÙ…...")
        
        try:
            conn = sqlite3.connect(self.knowledge_db)
            cursor = conn.cursor()
            
            cursor.execute(f'''
                DELETE FROM web_knowledge 
                WHERE created_at < datetime("now", "-{days} days")
            ''')
            
            deleted_count = cursor.rowcount
            conn.commit()
            conn.close()
            
            print(f"âœ… ØªÙ… Ø­Ø°Ù {deleted_count} Ø³Ø¬Ù„ Ù‚Ø¯ÙŠÙ…")
            return deleted_count
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù‚Ø¯ÙŠÙ…: {e}")
            return 0
    
    def optimize_categories(self):
        """ØªØ­Ø³ÙŠÙ† ÙˆØªÙ†Ø¸ÙŠÙ… Ø§Ù„ÙØ¦Ø§Øª"""
        print("ðŸ·ï¸  ØªØ­Ø³ÙŠÙ† ØªÙ†Ø¸ÙŠÙ… Ø§Ù„ÙØ¦Ø§Øª...")
        
        try:
            conn = sqlite3.connect(self.knowledge_db)
            cursor = conn.cursor()
            
            # ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙØ¦Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø­ØªÙˆÙ‰
            cursor.execute('''
                UPDATE web_knowledge 
                SET category = CASE 
                    WHEN title LIKE '%tutorial%' OR content LIKE '%tutorial%' THEN 'tutorials'
                    WHEN title LIKE '%guide%' OR content LIKE '%guide%' THEN 'guides'
                    WHEN title LIKE '%documentation%' OR content LIKE '%documentation%' THEN 'documentation'
                    WHEN title LIKE '%news%' OR content LIKE '%news%' THEN 'news'
                    WHEN title LIKE '%discussion%' OR content LIKE '%discussion%' THEN 'discussions'
                    ELSE 'general'
                END
                WHERE category = 'tutorials'  -- ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙØ¦Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ© ÙÙ‚Ø·
            ''')
            
            updated_count = cursor.rowcount
            conn.commit()
            
            # Ø¹Ø±Ø¶ ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯
            cursor.execute('''
                SELECT category, COUNT(*) 
                FROM web_knowledge 
                GROUP BY category 
                ORDER BY COUNT(*) DESC
            ''')
            categories = cursor.fetchall()
            
            conn.close()
            
            print(f"âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« {updated_count} Ø³Ø¬Ù„")
            print("ðŸ“Š ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯:")
            for category, count in categories:
                print(f"   - {category}: {count}")
                
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø³ÙŠÙ† Ø§Ù„ÙØ¦Ø§Øª: {e}")
    
    def generate_cleanup_report(self):
        """ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªÙ†Ø¸ÙŠÙ"""
        print("ðŸ“‹ ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªÙ†Ø¸ÙŠÙ...")
        
        analysis = self.analyze_content()
        
        if not analysis:
            return
        
        report = {
            "cleanup_date": datetime.now().isoformat(),
            "before_cleanup": analysis,
            "actions_taken": {},
            "after_cleanup": {}
        }
        
        # ØªÙ†ÙÙŠØ° Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª
        report["actions_taken"]["duplicates_removed"] = self.remove_duplicates()
        report["actions_taken"]["old_content_removed"] = self.remove_old_content(30)
        
        # ØªØ­Ø³ÙŠÙ† Ø§Ù„ÙØ¦Ø§Øª
        self.optimize_categories()
        
        # Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ
        report["after_cleanup"] = self.analyze_content()
        
        # Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
        os.makedirs("reports/diagnostics", exist_ok=True)
        report_file = f"reports/diagnostics/knowledge_cleanup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        with open(report_file, 'w') as f:
            json.dump(report, f, indent=2)
        
        print(f"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {report_file}")
        
        # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        print(f"\nðŸŽ¯ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙ†Ø¸ÙŠÙ:")
        print(f"   ðŸ“Š Ù‚Ø¨Ù„: {analysis['total_records']} Ø³Ø¬Ù„")
        print(f"   ðŸ“Š Ø¨Ø¹Ø¯: {report['after_cleanup']['total_records']} Ø³Ø¬Ù„")
        print(f"   ðŸ§¹ ØªÙ… Ø­Ø°Ù: {analysis['total_records'] - report['after_cleanup']['total_records']} Ø³Ø¬Ù„")
        print(f"   ðŸ·ï¸  ÙØ¦Ø§Øª Ù…ØªÙ†ÙˆØ¹Ø©: {report['after_cleanup']['categories_count']}")

if __name__ == "__main__":
    cleaner = KnowledgeCleaner()
    cleaner.generate_cleanup_report()
