#!/usr/bin/env python3
"""
Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù… - ÙŠÙ†Ø¸Ù… ÙˆÙŠØ±ØªØ¨ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹
"""

import sqlite3
import json
import re
from datetime import datetime

class KnowledgeProcessor:
    def __init__(self):
        self.knowledge_db = "data/knowledge/knowledge.db"
    
    def analyze_knowledge_base(self):
        """ØªØ­Ù„ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©"""
        conn = sqlite3.connect(self.knowledge_db)
        cursor = conn.cursor()
        
        print("ğŸ” ÙŠØ­Ù„Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©...")
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¹Ø§Ù…Ø©
        cursor.execute('SELECT COUNT(*) FROM web_knowledge')
        total_items = cursor.fetchone()[0]
        
        cursor.execute('SELECT AVG(quality_score) FROM web_knowledge')
        avg_quality = cursor.fetchone()[0] or 0
        
        cursor.execute('''
            SELECT category, COUNT(*) as count, AVG(quality_score) as avg_quality
            FROM web_knowledge 
            GROUP BY category 
            ORDER BY count DESC
        ''')
        categories = cursor.fetchall()
        
        print(f"ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©:")
        print(f"   Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¹Ù†Ø§ØµØ±: {total_items}")
        print(f"   Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¬ÙˆØ¯Ø©: {avg_quality:.1%}")
        
        print(f"\nğŸ“‹ Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª:")
        for category, count, avg_qual in categories:
            print(f"   â€¢ {category}: {count} Ø¹Ù†ØµØ± (Ø¬ÙˆØ¯Ø©: {avg_qual:.1%})")
        
        conn.close()
        return total_items, categories
    
    def extract_programming_patterns(self):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø¨Ø±Ù…Ø¬Ø© Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰"""
        conn = sqlite3.connect(self.knowledge_db)
        cursor = conn.cursor()
        
        cursor.execute('SELECT content FROM web_knowledge WHERE content LIKE "%def %" OR content LIKE "%class %"')
        code_contents = cursor.fetchall()
        
        patterns_found = []
        
        for content_tuple in code_contents:
            content = content_tuple[0]
            patterns = self.identify_patterns(content)
            patterns_found.extend(patterns)
        
        # Ø­ÙØ¸ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…ÙƒØªØ´ÙØ©
        for pattern in patterns_found:
            cursor.execute('''
                INSERT OR REPLACE INTO programming_patterns 
                (pattern_name, pattern_description, code_example, use_cases, category, difficulty, source_url)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (
                pattern['name'],
                pattern['description'],
                pattern['code_example'],
                pattern['use_cases'],
                pattern['category'],
                pattern['difficulty'],
                pattern.get('source_url', '')
            ))
        
        conn.commit()
        conn.close()
        
        print(f"âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ {len(patterns_found)} Ù†Ù…Ø· Ø¨Ø±Ù…Ø¬Ø©")
        return patterns_found
    
    def identify_patterns(self, content):
        """ØªØ­Ø¯ÙŠØ¯ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø¨Ø±Ù…Ø¬Ø© ÙÙŠ Ø§Ù„Ù…Ø­ØªÙˆÙ‰"""
        patterns = []
        
        # Ù†Ù…Ø· Ø§Ù„Ø¯Ø§Ù„Ø©
        function_matches = re.findall(r'def\s+(\w+)\s*\([^)]*\):\s*(.*?)(?=\n\s*\n|\Z)', content, re.DOTALL)
        for func_name, func_body in function_matches:
            if len(func_body.strip()) > 10:
                patterns.append({
                    'name': f'function_{func_name}',
                    'description': f'Ø¯Ø§Ù„Ø© {func_name} - {self.estimate_function_purpose(func_body)}',
                    'code_example': f"def {func_name}(...):\n{func_body[:200]}",
                    'use_cases': 'Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŒ ØªÙ†ÙÙŠØ° Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª',
                    'category': 'functions',
                    'difficulty': 'beginner'
                })
        
        # Ù†Ù…Ø· Ø§Ù„Ø´Ø±Ø·
        if_matches = re.findall(r'if\s+[^:]+:(.*?)(?=elif|else|\n\s*\n)', content, re.DOTALL)
        if len(if_matches) > 2:
            patterns.append({
                'name': 'conditional_logic',
                'description': 'Ù…Ù†Ø·Ù‚ Ø´Ø±Ø·ÙŠ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø´Ø±ÙˆØ·',
                'code_example': if_matches[0][:150],
                'use_cases': 'Ø§ØªØ®Ø§Ø° Ø§Ù„Ù‚Ø±Ø§Ø±Ø§ØªØŒ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø´Ø±ÙˆØ·',
                'category': 'control_flow',
                'difficulty': 'beginner'
            })
        
        # Ù†Ù…Ø· Ø§Ù„Ø­Ù„Ù‚Ø§Øª
        loop_matches = re.findall(r'(for\s+\w+\s+in\s+[^:]+:|while\s+[^:]+:)(.*?)(?=\n\s*\n)', content, re.DOTALL)
        if loop_matches:
            patterns.append({
                'name': 'loop_pattern',
                'description': 'Ù†Ù…Ø· Ø§Ù„Ø­Ù„Ù‚Ø§Øª Ø§Ù„ØªÙƒØ±Ø§Ø±ÙŠØ©',
                'code_example': loop_matches[0][0] + loop_matches[0][1][:100],
                'use_cases': 'Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§ØªØŒ Ø§Ù„ØªÙƒØ±Ø§Ø±',
                'category': 'loops',
                'difficulty': 'beginner'
            })
        
        return patterns
    
    def estimate_function_purpose(self, function_body):
        """ØªÙ‚Ø¯ÙŠØ± Ù‡Ø¯Ù Ø§Ù„Ø¯Ø§Ù„Ø© Ù…Ù† Ù…Ø­ØªÙˆØ§Ù‡Ø§"""
        body_lower = function_body.lower()
        
        if any(word in body_lower for word in ['calculate', 'sum', 'total', 'average']):
            return 'Ø¹Ù…Ù„ÙŠØ§Øª Ø­Ø³Ø§Ø¨ÙŠØ©'
        elif any(word in body_lower for word in ['read', 'write', 'file', 'open']):
            return 'Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª'
        elif any(word in body_lower for word in ['request', 'get', 'post', 'api']):
            return 'Ø§ØªØµØ§Ù„Ø§Øª Ø§Ù„Ø´Ø¨ÙƒØ©'
        elif any(word in body_lower for word in ['validate', 'check', 'verify']):
            return 'Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØµØ­Ø©'
        else:
            return 'Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¹Ø§Ù…Ø©'
    
    def generate_knowledge_index(self):
        """Ø¥Ù†Ø´Ø§Ø¡ ÙÙ‡Ø±Ø³ Ù„Ù„Ù…Ø¹Ø±ÙØ© Ù„Ù„Ø¨Ø­Ø« Ø§Ù„Ø³Ø±ÙŠØ¹"""
        conn = sqlite3.connect(self.knowledge_db)
        cursor = conn.cursor()
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø¯ÙˆÙ„ Ø§Ù„ÙÙ‡Ø±Ø³ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS knowledge_index (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                keyword TEXT,
                item_ids TEXT,
                category TEXT,
                relevance_score REAL
            )
        ''')
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰
        cursor.execute('SELECT id, content, category FROM web_knowledge')
        items = cursor.fetchall()
        
        keyword_index = {}
        
        for item_id, content, category in items:
            keywords = self.extract_keywords(content)
            
            for keyword, score in keywords.items():
                if keyword not in keyword_index:
                    keyword_index[keyword] = []
                keyword_index[keyword].append((item_id, score))
        
        # Ø­ÙØ¸ Ø§Ù„ÙÙ‡Ø±Ø³
        for keyword, items_list in keyword_index.items():
            item_ids = ','.join(str(item[0]) for item in items_list)
            avg_score = sum(item[1] for item in items_list) / len(items_list)
            
            cursor.execute('''
                INSERT OR REPLACE INTO knowledge_index 
                (keyword, item_ids, category, relevance_score)
                VALUES (?, ?, ?, ?)
            ''', (keyword, item_ids, category, avg_score))
        
        conn.commit()
        conn.close()
        
        print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ ÙÙ‡Ø±Ø³ Ø¨Ù€ {len(keyword_index)} ÙƒÙ„Ù…Ø© Ù…ÙØªØ§Ø­ÙŠØ©")
        return len(keyword_index)
    
    def extract_keywords(self, content):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰"""
        # Ø¥Ø²Ø§Ù„Ø© Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ±Ù‚ÙŠÙ… ÙˆØªØ­ÙˆÙŠÙ„ Ù„Ù„Ù†Øµ Ø§Ù„ØµØºÙŠØ±
        words = re.findall(r'\b[a-zA-Z]{4,}\b', content.lower())
        
        # ÙƒÙ„Ù…Ø§Øª Ø´Ø§Ø¦Ø¹Ø© ÙÙŠ Ø§Ù„Ø¨Ø±Ù…Ø¬Ø© (Ù„Ù„Ø§Ø³ØªØ¨Ø¹Ø§Ø¯)
        common_words = {'this', 'that', 'with', 'from', 'have', 'were', 'them', 'will', 'then', 'when'}
        programming_terms = {'function', 'class', 'method', 'object', 'variable', 'value', 'return'}
        
        word_freq = {}
        for word in words:
            if word not in common_words and word in programming_terms:
                word_freq[word] = word_freq.get(word, 0) + 1
        
        # Ø­Ø³Ø§Ø¨ Ø¯Ø±Ø¬Ø§Øª Ø§Ù„Ø£Ù‡Ù…ÙŠØ©
        max_freq = max(word_freq.values()) if word_freq else 1
        keyword_scores = {word: freq/max_freq for word, freq in word_freq.items()}
        
        return keyword_scores
    
    def create_knowledge_summary(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ø®Øµ Ù„Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©"""
        total_items, categories = self.analyze_knowledge_base()
        patterns_count = len(self.extract_programming_patterns())
        index_size = self.generate_knowledge_index()
        
        summary = {
            'summary_date': datetime.now().isoformat(),
            'total_knowledge_items': total_items,
            'programming_patterns': patterns_count,
            'search_index_size': index_size,
            'categories_available': len(categories),
            'status': 'knowledge_base_ready'
        }
        
        # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ø®Øµ
        with open('ai/memory/knowledge_summary.json', 'w') as f:
            json.dump(summary, f, indent=2)
        
        print(f"\nğŸ“š Ù…Ù„Ø®Øµ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©:")
        for key, value in summary.items():
            print(f"   {key}: {value}")
        
        return summary

def main():
    processor = KnowledgeProcessor()
    
    print("ğŸ§  Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…")
    print("=" * 40)
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©
    summary = processor.create_knowledge_summary()
    
    print(f"\nğŸ‰ Ø§ÙƒØªÙ…Ù„Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©!")
    print(f"   Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø¬Ø§Ù‡Ø²Ø© Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…")

if __name__ == "__main__":
    main()
