#!/usr/bin/env python3
"""
Advanced Architecture Audit for Hyper Factory
- ÙŠÙ„Ø®Ù‘Øµ Ø­Ø§Ù„Ø© Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© ÙÙŠ JSON + ØªÙ‚Ø±ÙŠØ± Ù†ØµÙŠ
"""

import json
import sqlite3
from pathlib import Path
from datetime import datetime

BASE = Path(__file__).resolve().parent

def bool_flag(v: bool) -> str:
    return "OK" if v else "MISSING"

def check_path(path: Path) -> bool:
    return path.exists()

def check_dir(path: Path) -> bool:
    return path.is_dir()

def check_file(path: Path) -> bool:
    return path.is_file()

def scan_data_lakehouse():
    dl = BASE / "data_lakehouse"
    zones = ["raw", "cleansed", "semantic", "serving", "catalog"]
    info = {
        "exists": check_dir(dl),
        "zones": {},
    }
    for z in zones:
        p = dl / z
        info["zones"][z] = {
            "exists": check_dir(p),
            "files": len(list(p.rglob("*"))) if p.exists() else 0,
        }
    return info

def scan_factories_and_stack():
    factories = BASE / "factories"
    stack = BASE / "stack"
    cfg = BASE / "config"

    return {
        "factories_dir": {
            "exists": check_dir(factories),
        },
        "stack_dir": {
            "exists": check_dir(stack),
        },
        "factory_config": {
            "factory_yaml": check_file(cfg / "factory.yaml"),
            "factory_manifest": check_file(cfg / "factory_manifest.yaml"),
        },
    }

def scan_agents():
    agents_dir = BASE / "agents"
    expected = [
        "debug_expert",
        "system_architect",
        "technical_coach",
        "knowledge_spider",
        "security_auditor",
        "document_generator",
        "patterns_engine",
        "quality_engine",
        "temporal_memory",
        "integration_hub",
    ]
    result = {
        "agents_root_exists": check_dir(agents_dir),
        "agents": {},
    }
    for name in expected:
        found = False
        if agents_dir.exists():
            for p in agents_dir.rglob("*"):
                if p.is_dir() and name in p.name:
                    found = True
                    break
        result["agents"][name] = {
            "status": bool_flag(found),
            "exists": found,
        }
    return result

def scan_integrations():
    integ_dir = BASE / "integrations"
    files = []
    if integ_dir.exists():
        for p in sorted(integ_dir.glob("*.py")):
            files.append(p.name)
    return {
        "root_exists": check_dir(integ_dir),
        "files": files,
        "has_github_api": "github_api.py" in files,
        "has_notifications": "notifications.py" in files,
    }

def scan_knowledge_db():
    db_path = BASE / "data" / "knowledge" / "knowledge.db"
    info = {
        "db_exists": check_file(db_path),
        "tables": {},
        "error": None,
    }
    if not info["db_exists"]:
        info["error"] = "knowledge.db not found"
        return info

    try:
        conn = sqlite3.connect(db_path)
        cur = conn.cursor()
        cur.execute("SELECT name FROM sqlite_master WHERE type='table';")
        tables = [r[0] for r in cur.fetchall()]
        for t in tables:
            try:
                cur.execute(f"SELECT COUNT(*) FROM {t}")
                count = cur.fetchone()[0]
            except Exception:
                count = None
            info["tables"][t] = count
        conn.close()
    except Exception as e:
        info["error"] = str(e)

    return info

def build_summary(audit):
    """
    ÙŠØ¨Ù†ÙŠ Ù…Ù„Ø®Øµ Ù†ØµÙŠ Ù…ÙˆØ¬Ù‡ Ù„Ù„Ù…Ø§Ù„Ùƒ/Ø§Ù„Ù…Ø¯ÙŠØ±
    """
    lines = []
    lines.append("ğŸ“Š Advanced Architecture Audit - Hyper Factory")
    lines.append(f"â° {audit['meta']['timestamp']}")
    lines.append("")

    # Data Lakehouse
    dl = audit["data_lakehouse"]
    lines.append("1) Data Lakehouse")
    if dl["exists"]:
        lines.append("   - data_lakehouse Ù…ÙˆØ¬ÙˆØ¯Ø© âœ…")
        for z, zi in dl["zones"].items():
            status = "âœ…" if zi["exists"] else "âŒ"
            lines.append(f"   - {z}: {status} (files={zi['files']})")
    else:
        lines.append("   - data_lakehouse ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© âŒ")
    lines.append("")

    # Factories / Stack
    fs = audit["factories_stack"]
    lines.append("2) Factories / Stack")
    lines.append(f"   - factories/: {'âœ…' if fs['factories_dir']['exists'] else 'âŒ'}")
    lines.append(f"   - stack/: {'âœ…' if fs['stack_dir']['exists'] else 'âŒ'}")
    lines.append(f"   - factory.yaml: {'âœ…' if fs['factory_config']['factory_yaml'] else 'âŒ'}")
    lines.append(f"   - factory_manifest.yaml: {'âœ…' if fs['factory_config']['factory_manifest'] else 'âŒ'}")
    lines.append("")

    # Agents
    ag = audit["agents"]
    lines.append("3) Agents / Ø§Ù„Ø¹Ù…Ø§Ù„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…ÙŠÙ†")
    lines.append(f"   - agents/: {'âœ…' if ag['agents_root_exists'] else 'âŒ'}")
    for name, info in ag["agents"].items():
        lines.append(f"   - {name}: {'âœ…' if info['exists'] else 'âŒ'}")
    lines.append("")

    # Integrations
    itg = audit["integrations"]
    lines.append("4) Integrations")
    lines.append(f"   - integrations/: {'âœ…' if itg['root_exists'] else 'âŒ'}")
    lines.append(f"   - github_api.py: {'âœ…' if itg['has_github_api'] else 'âŒ'}")
    lines.append(f"   - notifications.py: {'âœ…' if itg['has_notifications'] else 'âŒ'}")
    lines.append(f"   - Ù…Ù„ÙØ§Øª Ø£Ø®Ø±Ù‰: {', '.join(itg['files']) if itg['files'] else 'Ù„Ø§ ÙŠÙˆØ¬Ø¯'}")
    lines.append("")

    # Knowledge DB
    kdb = audit["knowledge_db"]
    lines.append("5) Knowledge DB")
    if not kdb["db_exists"]:
        lines.append("   - knowledge.db: âŒ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")
    else:
        lines.append("   - knowledge.db: âœ… Ù…ÙˆØ¬ÙˆØ¯")
        lines.append("   - Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ ÙˆØ¹Ø¯Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª:")
        for t, c in kdb["tables"].items():
            lines.append(f"     â€¢ {t}: {c}")
        if kdb["tables"].get("system_patterns", 0) == 0:
            lines.append("   âš ï¸ system_patterns ÙØ§Ø±Øº â†’ Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ù†Ù…Ø§Ø· ØºÙŠØ± Ù…ÙØ¹Ù‘Ù„ Ø¨Ø¹Ø¯.")
        if kdb["tables"].get("agent_memory", 0) == 0:
            lines.append("   âš ï¸ agent_memory ÙØ§Ø±Øº â†’ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ© ØºÙŠØ± Ù…ÙØ¹Ù‘Ù„Ø©.")
    lines.append("")

    # Ø¥Ø³ØªÙ†ØªØ§Ø¬ Ø³Ø±ÙŠØ¹
    lines.append("6) Executive Summary")
    lines.append("   - Ù…Ù†ØµØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©: Ø¬Ø§Ù‡Ø²Ø© âœ…")
    if dl["zones"].get("catalog", {}).get("exists") is False:
        lines.append("   - Data Catalog: Ù…ÙÙ‚ÙˆØ¯ âŒ (ÙŠØ¬Ø¨ Ø¨Ù†Ø§Ø¡ data_lakehouse/catalog).")
    if not fs["factories_dir"]["exists"] or not fs["stack_dir"]["exists"]:
        lines.append("   - factories/stack: ØºÙŠØ± Ù…ÙƒØªÙ…Ù„Ø© âŒ (Ø¨Ù†ÙŠØ© Ù…Ù†Ø·Ù‚ÙŠØ© Ù…ÙˆØ¬ÙˆØ¯Ø©ØŒ Ø§Ù„ÙÙŠØ²ÙŠØ§Ø¦ÙŠØ© Ù†Ø§Ù‚ØµØ©).")
    missing_advanced_agents = [
        n for n, info in ag["agents"].items()
        if not info["exists"] and n in ("patterns_engine","quality_engine","temporal_memory","integration_hub")
    ]
    if missing_advanced_agents:
        lines.append(f"   - Advanced Agents Ù†Ø§Ù‚ØµØ©: {', '.join(missing_advanced_agents)}")
    if kdb["tables"].get("system_patterns", 0) == 0:
        lines.append("   - Patterns Engine: Ù‡ÙŠÙƒÙ„ ÙÙ‚Ø· Ø¨Ø¯ÙˆÙ† Ø¨ÙŠØ§Ù†Ø§Øª.")
    if kdb["tables"].get("agent_memory", 0) == 0:
        lines.append("   - Temporal Memory: ØºÙŠØ± Ù…ÙØ¹Ù‘Ù„ (Ù„Ø§ ØªÙˆØ¬Ø¯ Ø³Ø¬Ù„Ø§Øª).")

    return "\n".join(lines)

def main():
    reports_dir = BASE / "reports"
    reports_dir.mkdir(parents=True, exist_ok=True)

    advanced_json = reports_dir / "advanced_audit.json"
    advanced_txt = reports_dir / "advanced_audit.txt"
    dashboard_json = reports_dir / "advanced_dashboard.json"

    audit = {
        "meta": {
            "timestamp": datetime.now().isoformat(timespec="seconds"),
            "base_dir": str(BASE),
        },
        "data_lakehouse": scan_data_lakehouse(),
        "factories_stack": scan_factories_and_stack(),
        "agents": scan_agents(),
        "integrations": scan_integrations(),
        "knowledge_db": scan_knowledge_db(),
    }

    # Ø­ÙØ¸ JSON
    with advanced_json.open("w", encoding="utf-8") as f:
        json.dump(audit, f, ensure_ascii=False, indent=2)

    # Ø­ÙØ¸ ØªÙ‚Ø±ÙŠØ± Ù†ØµÙŠ
    summary_text = build_summary(audit)
    with advanced_txt.open("w", encoding="utf-8") as f:
        f.write(summary_text)

    # ØªØ­Ø¯ÙŠØ« advanced_dashboard.json Ù…Ø¹ Ø£Ø®Ø° Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
    if dashboard_json.exists():
        backup = dashboard_json.with_suffix(".json.bak")
        dashboard_json.replace(backup)
    with dashboard_json.open("w", encoding="utf-8") as f:
        json.dump(
            {
                "meta": audit["meta"],
                "summary": {
                    "data_lakehouse_ok": audit["data_lakehouse"]["exists"],
                    "catalog_exists": audit["data_lakehouse"]["zones"]["catalog"]["exists"],
                    "factories_dir_exists": audit["factories_stack"]["factories_dir"]["exists"],
                    "stack_dir_exists": audit["factories_stack"]["stack_dir"]["exists"],
                    "advanced_agents": audit["agents"]["agents"],
                    "knowledge_db": {
                        "db_exists": audit["knowledge_db"]["db_exists"],
                        "tables": audit["knowledge_db"]["tables"],
                    },
                },
            },
            f,
            ensure_ascii=False,
            indent=2,
        )

    print("ğŸ”§ Advanced audit completed.")
    print(f"ğŸ“„ JSON  : {advanced_json}")
    print(f"ğŸ“„ TEXT  : {advanced_txt}")
    print(f"ğŸ“Š DASH  : {dashboard_json}")

if __name__ == "__main__":
    main()
