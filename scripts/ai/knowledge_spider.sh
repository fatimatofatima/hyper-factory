#!/bin/bash
# knowledge_spider.sh

set -e

BASE_DIR="$HOME/hyper-factory"
SPIDER_DIR="$BASE_DIR/ai/datasets"
LOGS_DIR="$BASE_DIR/logs/spider"

mkdir -p "$SPIDER_DIR"/{raw_content,cleaned_content,knowledge_chunks,spider_seeds}
mkdir -p "$LOGS_DIR"

log() {
    echo "$(date +'%Y-%m-%d %H:%M:%S') - $1" >> "$LOGS_DIR/spider.log"
    echo "$1"
}

echo "๐ธ๏ธ ุจุฏุก ุชุดุบูู ุนููุจูุช ุงููุนุฑูุฉ..."
echo "=========================================="

# 1. ุฅุนุฏุงุฏ ุงูุจุฐูุฑ
setup_seeds() {
    log "๐ฑ ุฅุนุฏุงุฏ ุงูุจุฐูุฑ ุงูุฃูููุฉ..."
    
    cat > "$SPIDER_DIR/spider_seeds/urls.txt" << 'URLS'
https://docs.python.org/3/tutorial/
https://fastapi.tiangolo.com/
https://docs.djangoproject.com/
https://realpython.com/
URLS
    
    log "โ ุงูุจุฐูุฑ ุฌุงูุฒุฉ: $SPIDER_DIR/spider_seeds/urls.txt"
}

# 2. ุฌูุจ ุงููุญุชูู
fetch_content() {
    local url="$1"
    local domain=$(echo "$url" | cut -d'/' -f3)
    local output_dir="$SPIDER_DIR/raw_content/$domain"
    mkdir -p "$output_dir"
    
    local filename=$(echo "$url" | md5sum | cut -d' ' -f1)
    local output_file="$output_dir/${filename}.html"
    
    log "๐ฅ ุฌูุจ ุงููุญุชูู ูู: $url"
    
    # ุงุณุชุฎุฏุงู wget ุฃู curl
    if command -v wget &> /dev/null; then
        if wget -q --timeout=30 -O "$output_file" "$url" 2>/dev/null; then
            log "โ ุชู ุงูุฌูุจ ุจุงุณุชุฎุฏุงู wget: $output_file"
            echo "$url" >> "$SPIDER_DIR/successful_fetches.txt"
            return 0
        fi
    fi
    
    if command -v curl &> /dev/null; then
        if curl -s --max-time 30 -o "$output_file" "$url" 2>/dev/null; then
            log "โ ุชู ุงูุฌูุจ ุจุงุณุชุฎุฏุงู curl: $output_file"
            echo "$url" >> "$SPIDER_DIR/successful_fetches.txt"
            return 0
        fi
    fi
    
    log "โ ูุดู ุงูุฌูุจ: $url"
    echo "$url" >> "$SPIDER_DIR/failed_fetches.txt"
    return 1
}

# 3. ุชูุธูู ุงููุญุชูู
clean_content() {
    local input_file="$1"
    local output_dir="$SPIDER_DIR/cleaned_content"
    mkdir -p "$output_dir"
    
    local base_name=$(basename "$input_file" .html)
    local output_file="$output_dir/${base_name}.txt"
    
    log "๐งน ุชูุธูู ุงููุญุชูู: $input_file"
    
    if [ -f "$input_file" ]; then
        # ุงุณุชุฎุฑุงุฌ ุงููุต ุงูุฃุณุงุณู (ูุญุงูุงุฉ - ูู ุงููุงูุน ูุณุชุฎุฏู lynx ุฃู python)
        echo "๐ ุงููุตุฏุฑ: $input_file" > "$output_file"
        echo "๐ ุชู ุงูุฌูุจ: $(date)" >> "$output_file"
        echo "==========================================" >> "$output_file"
        
        # ูุญุงููุฉ ุงุณุชุฎุฑุงุฌ ุงููุต ูู HTML
        if command -v lynx &> /dev/null; then
            lynx -dump "$input_file" >> "$output_file" 2>/dev/null
        else
            # ุจุฏูู ุจุณูุท ุฅุฐุง lynx ุบูุฑ ููุฌูุฏ
            grep -o '<title>[^<]*' "$input_file" | sed 's/<title>//' >> "$output_file" 2>/dev/null || true
            echo "๐ ูุญุชูู HTML (ุงุณุชุฎุฏู lynx ูุงุณุชุฎุฑุงุฌ ุฃูุถู)" >> "$output_file"
        fi
        
        log "โ ุชู ุงูุชูุธูู: $output_file"
    else
        log "โ ููู ุบูุฑ ููุฌูุฏ: $input_file"
    fi
}

# 4. ุชูุณูู ุฅูู ูุทุน
chunk_content() {
    local input_file="$1"
    local output_dir="$SPIDER_DIR/knowledge_chunks"
    mkdir -p "$output_dir"
    
    local base_name=$(basename "$input_file" .txt)
    
    log "โ๏ธ ุชูุณูู ุงููุญุชูู: $input_file"
    
    if [ -f "$input_file" ]; then
        # ุชูุณูู ุฅูู ูุทุน ~100 ุณุทุฑ
        split -d -l 100 "$input_file" "$output_dir/${base_name}_chunk_" 2>/dev/null || \
        cp "$input_file" "$output_dir/${base_name}_chunk_00"
        
        local chunk_count=$(ls "$output_dir/${base_name}_chunk_"* 2>/dev/null | wc -l)
        log "โ ุชู ุฅูุดุงุก $chunk_count ูุทุนุฉ: $output_dir/${base_name}_chunk_*"
    fi
}

# 5. ูุญุต ุงูุฌูุฏุฉ
quality_check() {
    log "๐ ูุญุต ุฌูุฏุฉ ุงููุนุฑูุฉ ุงููุฌูุนุฉ..."
    
    local total_chunks=$(find "$SPIDER_DIR/knowledge_chunks" -name "*chunk*" -type f 2>/dev/null | wc -l)
    local total_sources=$(find "$SPIDER_DIR/raw_content" -name "*.html" -type f 2>/dev/null | wc -l)
    
    log "๐ ุฅุญุตุงุฆูุงุช ุงูุฌูุฏุฉ:"
    log "   - ุฅุฌูุงูู ุงููุทุน ุงููุนุฑููุฉ: $total_chunks"
    log "   - ุฅุฌูุงูู ุงููุตุงุฏุฑ: $total_sources"
    log "   - ุงููุทุน ููู ูุตุฏุฑ: $((total_sources > 0 ? total_chunks / total_sources : 0))"
    
    if [ "$total_chunks" -gt 0 ]; then
        log "โ ุฌูุฏุฉ ุงููุนุฑูุฉ: ุฌูุฏุฉ ($total_chunks ูุทุนุฉ)"
    else
        log "โ๏ธ  ุฌูุฏุฉ ุงููุนุฑูุฉ: ุชุญุชุงุฌ ุชุญุณูู"
    fi
}

# ุงูุชูููุฐ ุงูุฑุฆูุณู
main() {
    log "๐ธ๏ธ ุจุฏุก ุฏูุฑุฉ ุฌูุน ุงููุนุฑูุฉ..."
    
    setup_seeds
    
    # ุฌูุจ ุงููุญุชูู ูู ุงูุจุฐูุฑ
    while IFS= read -r url; do
        if [ -n "$url" ]; then
            fetch_content "$url"
        fi
    done < "$SPIDER_DIR/spider_seeds/urls.txt"
    
    # ูุนุงูุฌุฉ ุงููุญุชูู ุงููุฌููุจ
    for domain_dir in "$SPIDER_DIR/raw_content"/*; do
        if [ -d "$domain_dir" ]; then
            for html_file in "$domain_dir"/*.html; do
                if [ -f "$html_file" ]; then
                    clean_content "$html_file"
                fi
            done
        fi
    done
    
    # ุชูุณูู ุงููุญุชูู ุงูููุธู
    for text_file in "$SPIDER_DIR/cleaned_content"/*.txt; do
        if [ -f "$text_file" ]; then
            chunk_content "$text_file"
        fi
    done
    
    # ูุญุต ุงูุฌูุฏุฉ ุงูููุงุฆู
    quality_check
    
    log "โ ุงูุชููุช ุฏูุฑุฉ ุฌูุน ุงููุนุฑูุฉ!"
    
    # ุนุฑุถ ุงููุชุงุฆุฌ
    echo ""
    echo "๐ฏ ูุชุงุฆุฌ ุงูุนููุจูุช:"
    echo "   - ุงููุทุน ุงููุนุฑููุฉ: $(find "$SPIDER_DIR/knowledge_chunks" -name "*chunk*" -type f 2>/dev/null | wc -l)"
    echo "   - ุงููุตุงุฏุฑ: $(find "$SPIDER_DIR/raw_content" -type d | tail -n +2 | wc -l)"
    echo "   - ุงูุณุฌูุงุช: $LOGS_DIR/spider.log"
}

main "$@"

# 6. ุชุญุฏูุซ ุฅุญุตุงุฆูุงุช ุงููุตูุน
update_factory_stats() {
    local chunk_count=$(find "$SPIDER_DIR/knowledge_chunks" -name "*chunk*" -type f 2>/dev/null | wc -l)
    
    log "๐ ุชุญุฏูุซ ุฅุญุตุงุฆูุงุช ุงููุตูุน: $chunk_count ูุทุนุฉ ูุนุฑููุฉ"
    
    # ูุญุงููุฉ ุชุญุฏูุซ API ุฅุฐุง ูุงู ุดุบุงู
    if curl -s http://localhost:9090/api/health > /dev/null 2>&1; then
        log "โ API ุดุบุงู - ุณูุชู ุชุญุฏูุซ ุงูุฅุญุตุงุฆูุงุช"
    else
        log "โ๏ธ  API ุบูุฑ ูุชุงุญ - ุณูุชู ุชุญุฏูุซ ุงูุฅุญุตุงุฆูุงุช ูุญููุงู"
    fi
}

# ูู ููุงูุฉ main() ูุถูู:
update_factory_stats
